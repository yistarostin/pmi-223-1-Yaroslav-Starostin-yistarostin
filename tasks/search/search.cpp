#include "search.h"

#include <cctype>
#include <functional>
#include <unordered_map>
#include <unordered_set>

template <typename F>
requires std::invocable<F&, int>
std::vector<std::string_view> Tokenize(std::string_view str, F fn) {
    std::vector<std::string_view> splitted_str;
    auto l = str.begin();
    for (auto r = str.begin(); r != str.end(); ++r) {
        if (fn(*r)) {
            if (l != r) {
                splitted_str.emplace_back(std::string_view{l, r});
            }
            l = r + 1;
        }
    }
    if (l != str.end()) {
        splitted_str.emplace_back(std::string_view{l, str.end()});
    }
    return splitted_str;
}

std::unordered_map<std::string_view, size_t> GenerateIDF(const std::vector<std::string_view>& tokenized_by_lines){
    std::unordered_map<std::string_view, size_t> IDF; // word -> IDS(word)
    for(std::string_view line : tokenized_by_lines){
        std::unordered_set<std::string_view> in_current_line;
        for(std::string_view word : Tokenize(line, [](char c){return !std::isalpha(c);})){
            if(in_current_line.count(word) == 0){
                in_current_line.insert(word);
                ++IDF[word];
            }
        }
    }
    return IDF;
}
std::unordered_set<std::string_view> GetInterestingLines(const std::vector<std::string_view>& tokenized_by_lines, const std::vector<std::string_view>& tokenized_query){
    std::unordered_set<std::string_view> interesting_lines;
    const std::unordered_set<std::string_view> words_bag(tokenized_query.begin(), tokenized_query.end());
    for(std::string_view line: tokenized_by_lines){
        auto tokenized_line = Tokenize(line, [](char c){return !std::isalpha(c);});
        if(std::any_of(tokenized_line.begin(), tokenized_line.end(), [&words_bag](std::string_view word){return words_bag.contains(word);})){
            interesting_lines.insert(line); //TODO: what if 2 lines and be equal ??? ðŸ˜¡ðŸ˜¡
        }
    }
    return interesting_lines;
}

long double GetLineTF(std::string_view line, std::string_view target_word){
    std::size_t total_words = line.size();
    std::size_t matched_words = 0;
    for(std::string_view word : Tokenize(line, [](char c){return !std::isalpha(c);})){
        if(target_word == word){
            ++matched_words;
        }
    }
    return static_cast<double>(matched_words) / static_cast<double>(total_words);
}

std::vector<std::string_view> Search(std::string_view text, std::string_view query, size_t results_count) {
    std::unordered_map<std::string_view, size_t> words_count; // word -> text.count(word)
    const auto tokenized_query{Tokenize(query, [](char c){return !std::isalpha(c);})};
    const auto tokenized_by_words{Tokenize(text, [](char c){return !std::isalpha(c);})};
    const auto tokenized_by_lines{Tokenize(text, iscntrl)};
    size_t text_length{tokenized_by_words.size()};
    const auto IDF{GenerateIDF(tokenized_by_lines)};
    const auto interesting_lines{GetInterestingLines(tokenized_by_lines, tokenized_query)};

    return {};
}
